{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read yelp.csv into a DataFrame.\n",
    "* Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "* Split the new DataFrame into training and testing sets, using the review text as the only feature and the star rating as the response.\n",
    "* Use CountVectorizer to create document-term matrices from X_train and X_test.\n",
    "**Hint:** If you run into a decoding error, instantiate the vectorizer with the argument decode_error='ignore'.\n",
    "* Use Naive Bayes to predict the star rating for reviews in the testing set, and calculate the accuracy.\n",
    "* Calculate the AUC.\n",
    "**Hint 1:** Make sure to pass the predicted probabilities to roc_auc_score, not the predicted classes.\n",
    "**Hint 2:** roc_auc_score will get confused if y_test contains fives and ones, so you will need to create a new object that contains ones and zeros instead.\n",
    "* Plot the ROC curve.\n",
    "* Print the confusion matrix, and calculate the sensitivity and specificity. Comment on the results.\n",
    "* Browse through the review text for some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any theories about why the model is incorrectly classifying these reviews?\n",
    "* Let's pretend that you want to balance sensitivity and specificity. You can achieve this by changing the threshold for predicting a 5-star review. What threshold approximately balances sensitivity and specificity?\n",
    "* Let's see how well Naive Bayes performs when all reviews are included, rather than just 1-star and 5-star reviews:\n",
    "* Define X and y using the original DataFrame from step 1. (y should contain 5 different classes.)\n",
    "* Split the data into training and testing sets.\n",
    "* Calculate the testing accuracy of a Naive Bayes model.\n",
    "* Compare the testing accuracy with the null accuracy.\n",
    "* Print the confusion matrix.\n",
    "* Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read yelp.csv into a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.576769</td>\n",
       "      <td>1.604806</td>\n",
       "      <td>1.056075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719525</td>\n",
       "      <td>1.563107</td>\n",
       "      <td>0.875944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.788501</td>\n",
       "      <td>1.306639</td>\n",
       "      <td>0.694730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.954623</td>\n",
       "      <td>1.395916</td>\n",
       "      <td>0.670448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944261</td>\n",
       "      <td>1.381780</td>\n",
       "      <td>0.608631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cool    useful     funny\n",
       "stars                              \n",
       "1      0.576769  1.604806  1.056075\n",
       "2      0.719525  1.563107  0.875944\n",
       "3      0.788501  1.306639  0.694730\n",
       "4      0.954623  1.395916  0.670448\n",
       "5      0.944261  1.381780  0.608631"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.groupby('stars').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 2, 3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.stars.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new DataFrame that only contains the 5-star and 1-star reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_text = text[(text.stars==5) | (text.stars==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_text.stars.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the new DataFrame into training and testing sets, using the review text as the only \n",
    "feature and the star rating as the response.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = _text.text\n",
    "y = _text.stars\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use CountVectorizer to create document-term matrices from X_train and X_test. \n",
    "Hint: If you run into a decoding error, instantiate the vectorizer with the argument decode_error='ignore'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 16825)\n",
      "(1022, 16825)\n"
     ]
    }
   ],
   "source": [
    "print (X_train_dtm.shape)\n",
    "print (X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Naive Bayes to predict the star rating for reviews in the testing set, and calculate the accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918786692759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the AUC. Hint 1: Make sure to pass the predicted probabilities to roc_auc_score, not the predicted classes.\n",
    "Hint 2: roc_auc_score will get confused if y_test contains fives and ones, so you will need to create a new object \n",
    "that contains ones and zeros instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940353585141\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_testnb = y_test.map({5:1, 1:0})\n",
    "\n",
    "print (metrics.roc_auc_score(y_testnb, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the ROC curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1136f40f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d312b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_testnb, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix, and calculate the sensitivity and specificity. Comment on the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 126  58]\n",
      " [  0  25 813]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_testnb, y_pred_class)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701670644391408\n"
     ]
    }
   ],
   "source": [
    "# TP    bottom right -> 813\n",
    "# TN    top left     -> 126\n",
    "# FP    top right    -> 58\n",
    "# FN    bottom left  -> 25\n",
    "\n",
    "# calculate the sensitivity\n",
    "# TP / float(TP + FN)\n",
    "print(813/(813 + 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6847826086956522\n",
      "False positive rate is 0.3152173913043478\n"
     ]
    }
   ],
   "source": [
    "# calculate the specificity\n",
    "# TN / float(TN + FP)\n",
    "\n",
    "spec = 126 / (126+58)\n",
    "print(spec)\n",
    "print(\"False positive rate is \" + str(1-spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity of correctly identifting a 5-star review is pretty high at 97%\n",
    "However, it is not very specific as only 69% of 1-star yelp reviews are correctly catagorized as 1-star, meaning that 32% of 1-star reviews are incorrectly assigned as 5-star reviews. Ack!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Browse through the review text for some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any theories about why the model is incorrectly classifying these reviews?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives\n",
    "X_test[y_test < y_pred_class].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I found Lisa G's while driving through phoenix with a friend. The exterior looked promising and we prepared ourselves for a treat. We were in for a a shock! We ordered the antipasto plate and while there were serious issues with it, it turned out to be the best thing we were served. I ordered the chicken rolatini (the special of the day) and it was just plain bad! The chicken was dry and under seasoned, the Rosemary potatoes were soggy  and the veggie medley  (squash, corn, green beans, etc.) was over cooked and the juices spilled over into the potatoes. It was one of the worst $17 meals that I have ever had! My friend ordered the veggie salad and it was one literal hot mess. Just horrible food! I see that others had the mini burgers and bowl of balls and found them to be tasty. I wish I had ordered those. As it is this is one place I would never revisit or recommend to a friend!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[3392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Went last night to Whore Foods to get basics to make pizza with, most clutch to the process was a three pack of yeast. Low and behold, the dirty hippie kids they have working there again didn't put something in the bag.\\n\\nAnd this time it was the yeast.\\n\\nI love the food there, but the employees are nothing more than entitled hippie kids from Scottsdale who can't be bothered to do their goddamn jobs! I am so sick of this crap with this corporation. Maybe its a Phoenix thing, or maybe its the hiring and firing processes of Whore Foods, but I am done shopping at any Whore Foods. In a place like Phoenix, where you have alternatives such as Sprouts, you'd think Whore Foods would smarten up.\\n\\nOr when you try to ask someone who works here where something is, and they just walk by with their nose high in the air. I understand its important to show your fellow dirt merchants that you're a super star, but I don't work with you, I contribute to your salary and over inflated set of benefits for a grocery clerk, so do your goddamn job. Useless little girl in need of a shower and orthodontist. \\n\\nBut alas, Whore Foods and its dirty hippie employees have alienated yet another person with a job and a degree into hating everything that place stands for.\\n\\nOh yea, one other thing, take the concealed firearm prohibition off of your stores. It didn't stop Jared Loughner from doing something horrid, and all it does is alienate law abiding citizens from their Constitutional rights. I understand you think that only parts of the Constitution should apply, but honestly I think you need to pull your collective heads out of your ass and take a shower.\\n\\nUseless motherf*&#$@s!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[9984]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives\n",
    "X_test[y_test > y_pred_class].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since I have ranted recently on poor customer service, and in the spirit of balance, here is a shining example of how easy it really is.\\n\\nLate last summer  I came home and was shocked to see two of my sunscreens looking quite vandalized. Upon further inspection, it appeared that while using a back mounted leaf blower, one of the landscape crew had brushed against them. The exhaust pipe must have ripped and burned the screen material as well. It was quite the nasty burned melted scar.\\n\\n After staring at it for several hours, I realized there was no virgin Mary, no Jesus, hell it just looked like burned grilled cheese without any deity or lesser apparitions whatsoever, regardless of the angle or my squint. So deciding there was no money to made on eBay, I set out to get them repaired.\\n\\nDid some online searching and decided to call AmeriZona. I explained the situation and was told they could repair them, but I would have to bring them in. These are some pretty large sun screens mind you and packing them into the convertible would have been a challenge.\\n\\nWhile pondering what to do the person helping me on the phone asked me if I could hold on. I could tell it was one of those thinking on your feet light bulb went off type can you hold requests.\\n\\nShe came back on the phone, informed me that she had a crew that was working close by and that she would ask one of the crew to swing by and pick up the screens for repair. She could not promise when they would be repaired, but for that convenience alone I was on board. She had already quoted me the price to repair the screens, and it was very reasonable considering some other online comparisons.\\n\\nSomeone showed up within a few hours to pick up the screens. He could not have been more accommodating, and it was obvious this guy had been working all day and was on his way home. \\n\\nA few days later, Mark  phoned me to tell me my screens were ready and to tell me he was going to drop them off on his way home! Needless to say Mark was also very pleasant to deal with. I believe he was at the time the sales manager. \\n\\nWhen he arrived, the screens looked great, matched the color of the others, even with the sun bleaching over several years. He even offered to put them in! \\n\\nThis experience was way beyond any customer service expectations. No extra charges for any of the above and beyond the call of duty efforts. Outstanding, and quite refreshing.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[6318]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hmm....It seems Naïve Bayes does not deal well with sarcasm - the prevelance of positive words in the reviews incorrectly classified as positive contains lots. Also lots of mentions of Scottsdale. The FP reviews also tend to be very long.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, with the false negatives (positive reviews incorrectly classified as negative), there are again lots of mentions of Scottsdale, and more long stories. More text does not improve the accuracy of Naïve Bayes. Because it treats every word as independent, it cannot take into account modifyers. For example, review 6318 talks a lot about their terrible circumstances, but were saved. It is likely that this was misclassified because most of the text is spent \"setting the scene\". sigh.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's pretend that you want to balance sensitivity and specificity. You can achieve this by changing the threshold for predicting a 5-star review. What threshold approximately balances sensitivity and specificity?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 0.83 Sensitivity and about 0.08 False Positive Rate? (jusdging by the ROC curve where I looked for the point on the curve that was closest to the top left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see how well Naive Bayes performs when all reviews are included, rather than just 1-star and 5-star reviews:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define X and y using the original DataFrame from step 1. (y should contain 5 different classes.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = text.text\n",
    "y = text.stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data into training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 5, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the testing accuracy of a Naive Bayes model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4712\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the testing accuracy with the null accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.3536\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure I understand this answer...it is 0.35, so my accuracy of 0.47 is marginally better. But what is the '4' for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55  14  24  65  27]\n",
      " [ 28  16  41 122  27]\n",
      " [  5   7  35 281  37]\n",
      " [  7   0  16 629 232]\n",
      " [  6   4   6 373 443]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a value for each of the stars. True labels are the rows 1-5. Predicted values are columns 1-5. \n",
    "\n",
    "[0,0] therefore is true value for 1-star and predicted value for 1-star -> TRUE POSITIVE.\n",
    "True positives will go along the diagonal. \n",
    "\n",
    "On either side of the diagonal is how many times each review is incorrectely classified. For example, if row [4] is 5-star reviews, then [4,0], which reads '6' means that 6 5-star reviews were incorrectly classified as a 1-star review (column 0 is 1-star predictions)\n",
    "\n",
    "[4,4] which reads '27' indicates that 1-star reviews were misclassified as 5-star reviews 27 times. \n",
    "\n",
    "In summary, we can see the Naïve Bayes misclassifies lower-rated reviews more often than higher-rated ones (top right region is low-star ratings, high-star predictions).\n",
    "\n",
    "*(Interpretation from reading http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
